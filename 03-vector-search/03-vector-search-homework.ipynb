{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Getting the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.82226324e-02, -4.01311293e-02,  3.86136100e-02, -1.78962495e-04,\n",
       "        8.92346650e-02, -5.04591130e-02, -1.05026821e-02,  3.71055938e-02,\n",
       "       -4.18714136e-02,  3.48085277e-02, -1.20702265e-02, -2.36942414e-02,\n",
       "        3.87899876e-02,  1.60988141e-02,  3.50747034e-02,  3.04755941e-03,\n",
       "        5.79672270e-02, -4.10627499e-02, -3.41552868e-02, -2.56396476e-02,\n",
       "       -3.55264395e-02,  1.42907910e-02, -1.62799843e-02,  3.21446396e-02,\n",
       "       -4.66897450e-02,  7.89185986e-02,  4.90160957e-02,  1.56760849e-02,\n",
       "       -1.69110298e-02,  2.26482041e-02,  5.60206249e-02, -3.98361534e-02,\n",
       "        6.77410141e-02, -1.20210061e-02,  1.12624047e-03, -1.94394924e-02,\n",
       "       -2.65951231e-02,  1.06177963e-02,  1.69687681e-02,  1.13488007e-02,\n",
       "       -2.97063068e-02,  5.25258482e-02, -1.41453156e-02,  4.61699590e-02,\n",
       "        1.17066344e-02, -2.38052998e-02, -6.32557869e-02, -1.92041937e-02,\n",
       "       -7.10595725e-03,  3.24167944e-02,  2.49618031e-02, -5.27500687e-03,\n",
       "        2.01149434e-02, -3.72371040e-02,  3.46405394e-02, -3.29310223e-02,\n",
       "       -2.01484617e-02,  5.07841678e-03, -4.55506667e-02,  7.89168850e-03,\n",
       "       -4.91713844e-02,  4.69897613e-02, -3.78925461e-06,  2.48839557e-02,\n",
       "       -2.96470989e-02,  6.69760397e-03,  3.58088128e-02, -7.18093803e-03,\n",
       "       -3.03277038e-02,  7.95785896e-03,  3.36150415e-02, -2.25491151e-02,\n",
       "       -3.62097509e-02, -2.03928854e-02, -2.70677288e-03, -8.15982148e-02,\n",
       "       -1.43992687e-02,  4.90568988e-02, -2.11568587e-02,  9.31650167e-04,\n",
       "        6.57264590e-02,  4.69609909e-02,  1.23655340e-02, -2.84593143e-02,\n",
       "       -2.57529113e-02,  1.46925626e-02, -5.53987324e-02, -3.05970367e-02,\n",
       "        5.75574003e-02,  2.81941816e-02, -1.30107179e-02, -2.08615139e-02,\n",
       "       -2.43034028e-02, -2.40275487e-02,  4.11576629e-02, -5.92422858e-02,\n",
       "       -1.69005676e-03,  4.00551930e-02,  2.43852958e-02, -1.10905012e-02,\n",
       "       -2.93892678e-02,  2.01825984e-02,  4.22845641e-03,  2.95343492e-02,\n",
       "        3.16522792e-02,  3.00930217e-02,  8.98857974e-03, -8.30621272e-02,\n",
       "       -2.24144161e-02,  1.82183068e-02, -5.66515587e-02, -4.21272442e-02,\n",
       "        3.27233039e-02, -2.10854877e-02, -4.79221856e-03,  1.90163162e-02,\n",
       "        4.55398001e-02, -9.62484162e-03, -2.30315905e-02, -3.52343209e-02,\n",
       "       -3.91419642e-02, -3.46547775e-02,  2.47354992e-02,  4.71566729e-02,\n",
       "        3.46270762e-02,  5.29963747e-02, -2.86405198e-02, -1.71784740e-02,\n",
       "       -1.30145969e-02, -5.79404570e-02,  3.99250686e-02, -5.88766858e-02,\n",
       "        4.57601398e-02,  2.09622569e-02, -1.52759906e-02,  3.25414725e-02,\n",
       "        2.08252929e-02, -2.48041973e-02, -4.24146950e-02,  2.95955334e-02,\n",
       "       -4.62034605e-02,  3.17028798e-02, -7.64972670e-03,  5.84931253e-03,\n",
       "       -3.90673950e-02,  8.11778568e-03, -3.60446386e-02,  6.34325668e-02,\n",
       "       -4.23139036e-02, -1.57088018e-03,  9.18295328e-03, -2.99420971e-02,\n",
       "       -2.27955598e-02, -9.86716803e-03,  2.94452552e-02,  1.75153613e-02,\n",
       "       -1.93444323e-02,  2.40449738e-02,  2.92803142e-02,  4.78738250e-04,\n",
       "        2.55402885e-02, -3.34960259e-02,  3.04799713e-02, -9.45274718e-03,\n",
       "        3.35257500e-02,  5.77760488e-02, -1.58550870e-02, -7.15147778e-02,\n",
       "        6.71668269e-04, -7.77698494e-03, -5.37220202e-02, -1.58578753e-02,\n",
       "        2.93348767e-02, -5.35058975e-02, -2.82785725e-02, -3.81729007e-02,\n",
       "        1.05947920e-03,  3.31669557e-03,  2.60325354e-02, -2.05704309e-02,\n",
       "       -2.55044010e-02, -2.73665451e-02,  2.12153196e-02, -3.17961425e-02,\n",
       "       -2.71618664e-02, -3.00257057e-02, -5.35570011e-02,  1.62939131e-02,\n",
       "        2.55569816e-03,  7.67827854e-02,  3.24226283e-02,  3.80413830e-02,\n",
       "       -2.25355476e-02, -4.81641740e-02,  2.26790383e-02,  1.25548402e-02,\n",
       "       -4.78155911e-02,  4.13825698e-02, -9.52940155e-03,  3.37111764e-02,\n",
       "        3.21243182e-02,  5.91824576e-02, -7.25298002e-02, -7.38687394e-03,\n",
       "       -3.22184600e-02,  3.09309512e-02,  5.23213930e-02,  3.24243680e-02,\n",
       "       -3.95455547e-02, -2.63985172e-02, -2.35443451e-02,  2.39195209e-03,\n",
       "        3.20996791e-02,  8.44291877e-03,  9.85340029e-03,  1.95926968e-02,\n",
       "        3.99372056e-02,  4.52750102e-02,  3.52183729e-02,  1.67367719e-02,\n",
       "        2.65720822e-02, -8.88592750e-03, -1.27367023e-02, -5.89370914e-02,\n",
       "       -2.89509390e-02,  2.18167678e-02, -4.62896489e-02, -5.12737175e-03,\n",
       "       -2.73846481e-02, -4.35680971e-02, -3.33959684e-02,  2.61663320e-03,\n",
       "        6.77051917e-02, -6.68664370e-03,  4.25815955e-02, -8.47999938e-03,\n",
       "       -4.45969552e-02, -4.92077172e-02,  2.54241731e-02,  3.41308936e-02,\n",
       "        4.66176458e-02,  3.41222882e-02, -3.89920175e-02,  6.68450445e-02,\n",
       "        6.32638037e-02, -1.53560890e-02, -6.43562234e-04,  1.88045427e-02,\n",
       "        1.10457614e-02, -2.76161283e-02,  4.89472300e-02, -6.65619448e-02,\n",
       "        4.41557867e-03, -8.06406979e-03, -7.56583139e-02,  5.20581976e-02,\n",
       "       -1.68674886e-02, -1.51841231e-02,  2.59556416e-02,  4.38797008e-03,\n",
       "        1.29939411e-02,  2.37958152e-02, -3.92605774e-02,  3.40799405e-03,\n",
       "       -4.65255454e-02, -5.80669381e-02, -4.86324355e-02,  3.85592692e-02,\n",
       "        1.58163458e-02, -3.55917998e-02, -6.13349266e-02, -4.66558896e-02,\n",
       "        3.48288901e-02, -3.00835799e-02, -3.80522646e-02,  5.35570905e-02,\n",
       "       -4.42222543e-02, -4.11476940e-02,  2.34689917e-02,  4.05343562e-05,\n",
       "       -2.18806695e-03, -2.06342782e-03, -4.33782376e-02, -6.21963700e-04,\n",
       "       -4.64339592e-02,  8.27863142e-02, -1.49072828e-02,  3.24270353e-02,\n",
       "        1.35792969e-02, -1.49162067e-03,  8.62602592e-02,  6.92183077e-02,\n",
       "        4.57405299e-03,  3.55522381e-03,  6.91157803e-02, -9.68690887e-02,\n",
       "        3.21001336e-02, -1.90142803e-02,  7.19640031e-02,  7.18858764e-02,\n",
       "        2.10939199e-02, -8.37235129e-04, -2.27937177e-02,  1.27857188e-02,\n",
       "        9.23394486e-02, -5.41783869e-02,  4.61493284e-02, -7.08937645e-03,\n",
       "       -3.20987180e-02, -3.81699689e-02, -4.22406010e-02,  5.16356602e-02,\n",
       "        1.07125295e-02, -5.59869073e-02, -2.29027923e-02,  3.15916538e-02,\n",
       "       -5.60135171e-02,  1.22198798e-02, -1.85766034e-02, -3.86151508e-03,\n",
       "        5.66245317e-02,  3.09959520e-02,  3.28163244e-02,  5.95071577e-02,\n",
       "       -1.15265641e-02,  2.45990753e-02,  1.98688800e-03,  3.61350365e-02,\n",
       "        7.19022527e-02,  6.74673263e-03, -2.22808383e-02,  3.80802564e-02,\n",
       "       -3.19979191e-02,  4.77899499e-02, -4.88462187e-02, -2.62966994e-02,\n",
       "       -9.14796349e-03, -3.70225050e-02, -2.10672691e-02,  3.66252474e-02,\n",
       "       -2.93571013e-03,  1.90015975e-02, -4.06738222e-02, -9.88850184e-03,\n",
       "       -1.32069802e-02, -1.84205901e-02, -3.04457247e-02, -1.17648160e-02,\n",
       "       -2.16221232e-02, -1.32907648e-02, -4.90810461e-02,  3.75494845e-02,\n",
       "        2.36799382e-02,  6.20983588e-03,  1.94518864e-02,  1.11170998e-02,\n",
       "       -1.27271796e-02, -1.16941258e-02, -4.15579267e-02,  3.03728529e-03,\n",
       "        3.35785858e-02,  2.02150829e-02, -5.23533225e-02, -1.03417682e-02,\n",
       "       -3.44100036e-02, -1.83595698e-02,  1.93091307e-03,  3.44448388e-02,\n",
       "       -2.83047985e-02,  7.25737493e-03,  5.40008694e-02, -2.32120026e-02,\n",
       "       -2.37849504e-02,  5.14849741e-03, -1.04727093e-02, -3.04510985e-02,\n",
       "       -1.45228375e-02,  5.83772063e-02,  6.24929462e-03,  1.76533274e-02,\n",
       "        2.71378141e-02, -2.07602680e-02, -4.82953247e-03,  4.38607223e-02,\n",
       "        4.89791222e-02, -1.84726361e-02,  2.23985352e-02,  2.48787273e-02,\n",
       "       -7.83606246e-03,  2.70838626e-02,  8.69911835e-02,  5.14607467e-02,\n",
       "        2.68816873e-02, -2.45198607e-02,  1.98570881e-02,  2.55423207e-02,\n",
       "       -4.49709557e-02,  1.18260281e-02, -5.71241081e-02,  6.86878264e-02,\n",
       "        2.32738368e-02,  4.34287563e-02,  1.60184782e-02,  3.36551443e-02,\n",
       "        1.18745044e-02,  1.84787270e-02,  2.18717530e-02,  8.06092750e-03,\n",
       "        2.65187398e-02, -1.67911090e-02, -1.14257457e-02,  5.79695925e-02,\n",
       "        2.19955500e-02, -7.88591579e-02,  4.26270962e-02, -7.00563118e-02,\n",
       "        5.12132496e-02,  2.96158213e-02,  4.99608517e-02,  9.40515008e-03,\n",
       "       -4.73498255e-02,  4.21216711e-02, -1.81927197e-02, -7.69210905e-02,\n",
       "        9.72859934e-03, -6.79067746e-02,  1.55992275e-02,  2.72873323e-02,\n",
       "        4.54436848e-03, -2.10014195e-03,  7.53397048e-02,  1.33479061e-03,\n",
       "       -1.99394710e-02, -5.24484478e-02,  3.05674900e-03,  1.98292192e-02,\n",
       "        2.39940677e-02,  1.24235963e-02,  1.47050088e-02,  1.03529394e-02,\n",
       "       -4.38815244e-02,  4.75225970e-02,  3.21548954e-02,  6.52188959e-04,\n",
       "       -2.02529635e-02,  4.32258733e-02, -2.71597076e-02,  1.38091762e-02,\n",
       "       -3.86391282e-02,  2.84993295e-02, -2.27454072e-03,  3.99672166e-02,\n",
       "        1.53476838e-02,  1.32415816e-02, -7.11276978e-02,  3.93648297e-02,\n",
       "        2.51131561e-02, -2.36388072e-02,  1.80941615e-02, -2.43954603e-02,\n",
       "        2.19320087e-03,  3.75051610e-02,  1.56092485e-02,  7.14066206e-03,\n",
       "       -3.41360085e-02,  7.57618388e-03,  2.62274519e-02,  1.14289131e-02,\n",
       "        3.52655649e-02,  2.13692500e-03, -4.56286641e-03, -2.63882577e-02,\n",
       "        6.55588135e-02,  6.00263998e-02, -3.54714356e-02, -1.01350788e-02,\n",
       "        2.56268661e-02, -1.02697223e-01,  3.54785398e-02, -6.22319579e-02,\n",
       "       -1.14733623e-02, -3.44269746e-03,  1.05506962e-03, -2.81984941e-03,\n",
       "        6.26723096e-02, -4.57265377e-02,  1.70463156e-02, -8.05482715e-02,\n",
       "        1.55107342e-02, -2.58680462e-04,  2.01547667e-02,  8.79568327e-03,\n",
       "        2.62557641e-02,  8.31547135e-04, -3.23719904e-02, -5.27925268e-02,\n",
       "        1.55638522e-02,  1.15739340e-02, -2.99572223e-03, -8.24663136e-03,\n",
       "       -3.26189026e-02, -7.73414895e-02, -4.12967317e-02, -2.21012365e-02,\n",
       "        4.75401338e-03, -1.25991050e-02,  1.07522868e-02,  4.99581918e-02,\n",
       "        2.15218347e-02,  2.69317217e-02,  3.28039378e-02,  7.46342912e-03,\n",
       "        1.83877200e-02, -2.74958033e-02, -9.13316663e-03, -1.22791072e-02,\n",
       "        2.07575988e-02,  1.40681816e-02,  1.09913489e-02, -2.26451810e-02,\n",
       "        6.41366020e-02, -1.79608855e-02, -4.23230976e-02, -1.88528933e-03,\n",
       "       -3.59299891e-02,  1.20294252e-02,  1.00361658e-02,  6.56100735e-02,\n",
       "        2.87166145e-02,  2.78465077e-02, -5.23849651e-02,  3.18163298e-02,\n",
       "       -4.65675592e-02,  1.38317375e-02,  2.83224452e-02,  7.78377615e-03,\n",
       "       -9.74422693e-03, -3.97435874e-02, -2.49804817e-02, -2.32911371e-02,\n",
       "       -2.11589225e-02, -6.84603816e-03, -1.95434950e-02, -2.29272209e-02,\n",
       "       -1.46510517e-02, -2.22449191e-02, -1.09536527e-02, -3.67134139e-02,\n",
       "       -1.84324607e-02, -1.04103135e-02, -8.88099987e-03, -1.47620477e-02,\n",
       "       -2.92523745e-02,  1.00569930e-02,  2.28201579e-02,  1.42324239e-03,\n",
       "       -2.35474389e-02, -2.39605643e-02,  5.40141016e-02, -2.16813106e-02,\n",
       "        1.94904692e-02, -3.11478619e-02, -1.54090049e-02, -1.45635633e-02,\n",
       "        5.81610277e-02,  3.05503197e-02, -5.09665441e-03, -1.68099739e-02,\n",
       "       -3.46655324e-02, -2.07241327e-02, -4.60087992e-02,  2.22177268e-03,\n",
       "       -4.44852859e-02,  1.13986861e-02,  3.25434655e-02, -7.11341426e-02,\n",
       "       -2.52612922e-02, -1.93928014e-02,  1.29123162e-02, -3.82378623e-02,\n",
       "       -1.61820985e-02,  3.58506851e-02,  5.04317321e-02, -4.06109774e-03,\n",
       "        1.62504502e-02, -7.24662319e-02,  2.72171535e-02,  1.78223941e-02,\n",
       "        1.37028992e-02,  2.36819740e-02,  2.59892493e-02,  4.08843197e-02,\n",
       "        6.46983413e-03, -1.15187699e-02, -2.65878905e-02,  9.67551395e-03,\n",
       "       -5.31226397e-02,  8.27110780e-04,  1.87265724e-02, -2.92991032e-03,\n",
       "        2.49405019e-02, -1.47512536e-02,  1.41258920e-02,  4.05029953e-02,\n",
       "       -1.27287935e-02, -6.76722601e-02,  4.83829305e-02,  4.07700278e-02,\n",
       "        1.98604669e-02,  3.03293820e-02,  2.63720807e-02,  5.23594171e-02,\n",
       "       -3.34631652e-02, -9.35082417e-03,  1.69177596e-02,  4.34683859e-02,\n",
       "        3.83584537e-02,  4.47563045e-02,  1.90878864e-02, -1.47993462e-02,\n",
       "       -4.34140023e-03,  1.08403321e-02,  4.95933788e-03, -1.63312461e-02,\n",
       "       -1.97148649e-03, -4.17675190e-02,  6.56750649e-02, -6.79402798e-02,\n",
       "        4.33393987e-03, -1.69463195e-02,  2.51758937e-02,  2.56763734e-02,\n",
       "        1.15081004e-03, -1.54735623e-02, -7.34510692e-03, -5.32572977e-02,\n",
       "        3.48775601e-03, -1.38180079e-02, -5.89081980e-02,  2.92864931e-03,\n",
       "        5.04819155e-02,  3.35808843e-03, -8.88556913e-02, -3.84001061e-02,\n",
       "       -2.22147498e-02, -2.82134227e-02, -5.42562734e-03,  2.85600722e-02,\n",
       "       -4.50811125e-02,  7.93275423e-04,  8.93172249e-02,  1.16104521e-02,\n",
       "       -3.18007804e-02,  2.66567338e-02,  2.71802731e-02,  1.89267471e-02,\n",
       "       -2.06058510e-02, -3.02396901e-02, -2.85009332e-02, -3.13029811e-02,\n",
       "       -1.97962951e-02, -6.64771954e-03, -1.67978071e-02, -1.99808050e-02,\n",
       "       -5.34575768e-02, -4.45697020e-04, -2.96823252e-02,  4.37867604e-02,\n",
       "       -1.00504141e-02, -1.09997308e-02,  2.21025907e-02, -3.46549340e-02,\n",
       "        2.11835969e-02,  1.56232882e-02,  2.64695659e-02, -2.34831404e-02,\n",
       "        2.44938545e-02,  4.38888744e-02,  7.06144562e-03, -1.21593736e-02,\n",
       "        1.87902208e-02, -6.91950135e-03,  1.30047044e-02,  1.27160801e-02,\n",
       "       -2.23637535e-03,  2.10031178e-02,  6.99695945e-02,  3.16452309e-02,\n",
       "       -2.35832594e-02,  4.63547092e-03, -6.60418859e-03, -3.26112136e-02,\n",
       "        7.33723491e-02, -8.55090916e-02, -4.05770056e-02,  2.57487409e-02,\n",
       "       -5.12588806e-02,  6.70370013e-02, -1.24505861e-02, -8.91838595e-02,\n",
       "        5.48583530e-02, -4.54949215e-02, -3.45564783e-02, -7.73074776e-02,\n",
       "        4.11657766e-02, -4.30639274e-02,  2.70703714e-02,  3.20440046e-02,\n",
       "       -4.77701947e-02, -1.56586487e-02,  1.72707271e-02, -5.23967259e-02,\n",
       "       -7.17989206e-02,  4.30010818e-03,  7.25962454e-05,  5.29346839e-02,\n",
       "       -3.14253606e-02,  1.90560911e-02,  2.56206375e-02,  7.90969655e-02,\n",
       "        2.13809758e-02, -2.44315211e-02, -1.42572941e-02,  3.64166759e-02,\n",
       "        4.89886776e-02,  2.09607705e-02, -4.13178541e-02,  4.09340262e-02,\n",
       "       -1.21459804e-01,  6.68874606e-02, -3.10793548e-04, -6.26344001e-03,\n",
       "        3.98600474e-02,  5.48594259e-02, -1.15817979e-01,  5.31956367e-02,\n",
       "       -4.32697088e-02,  4.33376282e-02,  2.90152356e-02, -8.89771655e-02,\n",
       "       -2.17882469e-02,  1.54281510e-02,  3.62120010e-02, -9.14942101e-02,\n",
       "       -3.93840950e-03, -3.60860527e-02, -7.26090558e-03,  8.90834164e-03,\n",
       "       -5.32953702e-02,  3.61573435e-02,  8.56205896e-02, -1.42062530e-02,\n",
       "        2.44348999e-02,  1.94476394e-03,  5.81038073e-02, -2.16630083e-02,\n",
       "        2.43256092e-02, -2.31525023e-03, -1.37540710e-03,  5.89746349e-02,\n",
       "        8.06515571e-03, -5.71862329e-03,  2.14907397e-02, -2.76927296e-02,\n",
       "       -3.97252701e-02,  3.13827805e-02,  1.40228565e-03,  5.06811477e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "embedding_model.encode(user_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, first value of the resulting vector is `7.82226324e-02`, i.e., ~ $0.07$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Prepare the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looping over the documents to filter the documents and create a list of documents only with the questions for \"machine-learning-zoomcamp\". we need every existing info of the documents containing the questions for \"machine-learning-zoomcamp\" to be able to find the most similar question to the user question. let's filter out every document that is not related to \"machine-learning-zoomcamp\" and keep the remaining documents. 'documents' is a dictionary with the following keys: 'id', 'course', 'module', 'lesson', 'content'. 'course' is a list with one element, 'machine-learning-zoomcamp'. 'module' is a string with the format 'module-<number>'. 'lesson' is a string with the format 'lesson-<number>'. 'content' is a string with the content of the document.\n",
    "\n",
    "ml_zoomcamp_documents = []\n",
    "for doc in documents:\n",
    "    if doc['course'] == 'machine-learning-zoomcamp':\n",
    "        ml_zoomcamp_documents.append(doc)\n",
    "\n",
    "len(ml_zoomcamp_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'How do I sign up?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'id': '0227b872'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_zoomcamp_documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the embeddings\n",
    "Now for each document, we will create an embedding for both question and answer fields.\n",
    "\n",
    "We want to put all of them into a single matrix `X`:\n",
    "\n",
    "- Create a list `embeddings` \n",
    "- Iterate over each document \n",
    "- `qa_text = f'{question} {text}'`\n",
    "- compute the embedding for `qa_text`, append to `embeddings`\n",
    "- At the end, let `X = np.array(embeddings)` (`import numpy as np`) \n",
    "\n",
    "What's the shape of X? (`X.shape`). Include the parantheses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list called 'embeddings'\n",
    "# Now for each document, we will create an embedding for both question and answer fields.\n",
    "\n",
    "# We want to put all of them into a single matrix `X`:\n",
    "\n",
    "# - Create a list `embeddings` \n",
    "# - Iterate over each document \n",
    "# - qa_text = f'{question} {text}'\n",
    "# - compute the embedding for `qa_text`, append to `embeddings`\n",
    "# - At the end, let `X = np.array(embeddings)` (`import numpy as np`) \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "embeddings = []\n",
    "for doc in ml_zoomcamp_documents:\n",
    "    qa_text = f'{doc[\"question\"]} {doc[\"text\"]}'\n",
    "    embeddings.append(embedding_model.encode(qa_text))\n",
    "\n",
    "X = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 768)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of X: (375, 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Search\n",
    "We have the embeddings and the query vector. Now let's compute the \n",
    "cosine similarity between the vector from Q1 (let's call it `v`) and the matrix from Q2. \n",
    "\n",
    "The vectors returned from the embedding model are already\n",
    "normalized (you can check it by computing a dot product of a vector\n",
    "with itself - it should return something very close to 1.0). This means that in order\n",
    "to compute the coside similarity, it's sufficient to \n",
    "multiply the matrix `X` by the vector `v`:\n",
    "\n",
    "\n",
    "```python\n",
    "scores = X.dot(v)\n",
    "```\n",
    "\n",
    "What's the highest score in the results?\n",
    "\n",
    "- 65.0 \n",
    "- 6.5\n",
    "- 0.65\n",
    "- 0.065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.89217472e-01,  4.35050964e-01,  2.20572710e-01,  1.28085911e-01,\n",
       "        3.28754783e-01,  4.58999842e-01,  4.48931158e-01,  2.70170718e-01,\n",
       "        2.13975042e-01,  3.39745700e-01,  1.63339168e-01,  3.15918058e-01,\n",
       "        1.53620597e-02,  4.14240599e-01,  6.50657535e-01,  4.12786633e-01,\n",
       "        2.02390462e-01,  4.71707582e-01,  3.74821484e-01,  3.53319287e-01,\n",
       "        4.50558513e-01,  1.85430795e-01,  3.45527172e-01,  8.22948888e-02,\n",
       "       -2.19077207e-02, -4.64249849e-02,  8.60690624e-02,  9.87197086e-02,\n",
       "       -2.14188509e-02,  1.28752766e-02,  2.54870132e-02,  3.66865620e-02,\n",
       "        4.56339158e-02, -2.05278452e-02,  1.82661451e-02,  3.39788869e-02,\n",
       "        1.66492118e-03,  1.03211123e-02,  3.40170003e-02, -2.65231114e-02,\n",
       "       -4.11910079e-02, -4.97983247e-02, -6.20347112e-02, -7.63558224e-03,\n",
       "        4.61617485e-02,  6.95947558e-03,  4.77613024e-02, -9.97874886e-04,\n",
       "       -5.60125150e-02, -5.96207082e-02,  2.05209255e-01, -1.16968535e-01,\n",
       "       -2.34159492e-02, -1.52458623e-02, -6.83511421e-03, -8.61714110e-02,\n",
       "        2.02637464e-02, -2.51591839e-02,  4.21298668e-04, -3.79211940e-02,\n",
       "       -3.21441442e-02,  2.48612508e-01,  2.12661564e-01,  2.87320148e-02,\n",
       "        5.64015564e-03,  2.83871032e-02,  1.02311999e-01,  1.08430363e-01,\n",
       "        4.45670784e-02,  5.62139861e-02, -1.25656992e-01,  6.16899459e-03,\n",
       "        7.16236793e-03, -5.59203923e-02, -4.92568016e-02, -6.11873791e-02,\n",
       "        2.45293789e-02,  1.35819800e-02, -4.08512056e-02, -1.22759659e-02,\n",
       "        7.87671879e-02, -4.09776792e-02,  2.84444168e-03,  3.54052000e-02,\n",
       "        7.06089288e-03, -7.25120753e-02,  8.09859410e-02,  2.13899866e-01,\n",
       "        5.30422702e-02,  5.03776968e-02, -3.79603058e-02, -2.42292825e-02,\n",
       "       -1.34441536e-02,  7.92890787e-02, -4.85011842e-03, -4.29112054e-02,\n",
       "       -3.20610292e-02,  6.69905022e-02, -8.40562582e-03, -1.32086903e-01,\n",
       "       -1.15119666e-03,  4.14729230e-02, -1.31331816e-01, -3.80731970e-02,\n",
       "        6.47670403e-03,  8.36595446e-02,  2.45577432e-02, -6.55223876e-02,\n",
       "       -6.91722333e-02,  5.12287170e-02,  4.83926572e-03,  5.39998636e-02,\n",
       "       -2.80694161e-02, -7.57022202e-02, -1.05883293e-01,  2.03204174e-02,\n",
       "        1.69167146e-02, -2.74920110e-02,  7.05348141e-03, -6.26005754e-02,\n",
       "       -1.31930009e-01,  5.10979742e-02,  1.47758454e-01, -3.40152755e-02,\n",
       "       -3.57092693e-02,  1.55357160e-02, -1.18726389e-02,  7.73691237e-02,\n",
       "        4.35771942e-02, -6.61863238e-02,  2.52171040e-01,  4.70676236e-02,\n",
       "       -7.70065784e-02,  3.79015580e-02,  1.35743022e-01, -7.73303211e-03,\n",
       "       -4.33597974e-02,  7.42026418e-02,  1.12941265e-02, -4.40410711e-02,\n",
       "        3.28043520e-01,  3.83173302e-03, -4.73500928e-03,  7.93514773e-04,\n",
       "       -6.67457730e-02,  1.09346230e-02,  6.56733755e-03, -2.20779888e-03,\n",
       "       -2.48793233e-03,  9.11663193e-03, -1.64973401e-02,  6.57348931e-02,\n",
       "        1.86012596e-01,  1.81024402e-01,  1.19438395e-02,  9.31540653e-02,\n",
       "        8.77034292e-02,  4.60377410e-02, -3.29314396e-02,  8.97290260e-02,\n",
       "        4.92409356e-02, -1.51443928e-02,  1.82684109e-01, -9.11698490e-03,\n",
       "        3.82712558e-02, -2.85148844e-02, -2.32420750e-02, -1.17940314e-01,\n",
       "        8.04635435e-02, -3.96182314e-02, -2.93325968e-02, -2.86630411e-02,\n",
       "        5.59824221e-02,  2.05440279e-02,  4.35310416e-02,  8.72728415e-03,\n",
       "        9.05859023e-02,  4.16058600e-02, -1.07162192e-01, -1.74159203e-02,\n",
       "        3.76869403e-02,  5.74280787e-03,  7.82681853e-02, -1.67808123e-02,\n",
       "       -2.49322876e-02,  1.17247626e-01,  1.92652363e-02,  2.24364176e-02,\n",
       "        6.70091957e-02,  1.04418255e-01,  9.30422023e-02,  1.11064196e-01,\n",
       "       -1.55649353e-02, -8.05810560e-04,  1.06892362e-01, -5.77538759e-02,\n",
       "        9.22656357e-02,  8.57100785e-02, -5.62501140e-04,  6.70872629e-02,\n",
       "       -8.66510160e-03,  1.68557428e-02,  6.78132176e-02,  3.23787555e-02,\n",
       "        1.53096735e-01,  3.46215814e-03,  9.72393155e-02,  7.46944919e-03,\n",
       "        5.92091233e-02, -4.15483397e-03,  8.42872113e-02, -2.21288316e-02,\n",
       "       -2.13754661e-02, -3.08730844e-02,  1.13827303e-01, -5.18076383e-02,\n",
       "       -3.82554643e-02,  1.21785194e-01,  2.12654956e-02,  1.00384027e-01,\n",
       "        1.02448732e-01, -8.57205838e-02,  9.46159065e-02, -5.88216400e-03,\n",
       "       -8.54180902e-02, -5.48273921e-02, -2.86803134e-02,  6.51873052e-02,\n",
       "       -8.90593529e-02,  2.25946773e-02,  2.30075046e-03,  1.26689658e-01,\n",
       "        9.92651731e-02,  1.21937111e-01,  8.56218208e-03,  5.68377674e-02,\n",
       "        1.07429966e-01,  3.81353796e-02,  3.70677859e-02,  5.04433662e-02,\n",
       "        5.89761995e-02,  1.46543551e-02,  5.39241806e-02, -1.02875428e-03,\n",
       "        4.38618325e-02, -5.49201295e-02,  9.17540565e-02,  8.76394659e-02,\n",
       "        1.08017363e-02,  6.35476932e-02,  7.61534125e-02, -1.20977789e-01,\n",
       "        3.12572308e-02,  1.07315436e-01,  2.11034250e-02, -1.16809756e-01,\n",
       "       -7.75170624e-02, -3.13895196e-02,  9.74868797e-03, -2.51134522e-02,\n",
       "        7.61513086e-03, -5.23268841e-02,  8.75004455e-02,  1.02829620e-01,\n",
       "        5.21386117e-02,  1.17953429e-02, -6.86212927e-02, -3.29190232e-02,\n",
       "        1.25220157e-02,  4.99132909e-02,  1.76850967e-02,  5.28944358e-02,\n",
       "        3.63487005e-02, -3.74852344e-02,  4.61162161e-03, -1.40474647e-01,\n",
       "       -8.45708996e-02, -1.63268112e-02, -2.33855192e-03,  9.91798490e-02,\n",
       "        8.12099278e-02, -1.15462989e-02, -1.46433581e-02,  5.92481792e-02,\n",
       "       -2.45577320e-02,  2.28129178e-02,  1.75959393e-02,  4.81147394e-02,\n",
       "        1.09546762e-02, -2.97679491e-02, -4.04059142e-03,  8.05019513e-02,\n",
       "        5.23830280e-02,  6.93680793e-02,  4.00665216e-03, -1.52228251e-02,\n",
       "       -5.35551179e-03,  2.97431145e-02,  2.86108311e-02,  5.79051860e-03,\n",
       "        8.26218277e-02, -6.90160412e-03,  8.27183276e-02,  3.15403640e-02,\n",
       "        7.90223181e-02,  1.35424182e-01, -6.60495088e-03,  3.40357125e-02,\n",
       "       -6.04556501e-02,  2.99351290e-04,  4.17965576e-02,  2.76402645e-02,\n",
       "        2.20876466e-02,  8.75888020e-02,  3.75620015e-02,  1.02919862e-02,\n",
       "        2.79955771e-02,  1.11261226e-01, -4.82460484e-02,  2.56312322e-02,\n",
       "        1.01506598e-02,  1.10233322e-01,  8.72282386e-02,  1.99888796e-01,\n",
       "        1.58133298e-01,  5.12093492e-03, -5.28741442e-02,  1.38271004e-01,\n",
       "        3.39297801e-02,  3.29888433e-01,  1.50600195e-01,  9.16855037e-02,\n",
       "        2.34560519e-02,  2.25460172e-01,  1.53260052e-01, -7.96022359e-03,\n",
       "        1.47858679e-01,  5.57384044e-02,  4.80688438e-02,  7.96172675e-03,\n",
       "        1.04084641e-01, -1.46763742e-01,  1.24577627e-01,  5.08548319e-03,\n",
       "        9.75180566e-02, -3.69484201e-02, -1.76295899e-02,  6.71321601e-02,\n",
       "       -4.29843366e-02,  8.52766167e-03,  3.95145044e-02,  4.70581800e-02,\n",
       "       -2.83395946e-02, -2.89895236e-02, -4.38461788e-02, -1.16550513e-02,\n",
       "        4.59899418e-02,  1.22448066e-02,  9.40720439e-02,  6.48718998e-02,\n",
       "       -5.06505109e-02,  1.39609948e-01,  1.91962466e-01,  1.55291185e-01,\n",
       "       -1.94995254e-02,  1.88640915e-02,  6.77654333e-03,  3.05331275e-02,\n",
       "        2.56959368e-02,  7.66611099e-02, -7.14630187e-02,  4.56990391e-01,\n",
       "        1.33357570e-01,  6.59828931e-02,  2.52122641e-01], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have the embeddings and the query vector. Now let's compute the \n",
    "# cosine similarity between the vector from Q1 (let's call it `v`) and the matrix from Q2. \n",
    "\n",
    "# The vectors returned from the embedding model are already\n",
    "# normalized (you can check it by computing a dot product of a vector\n",
    "# with itself - it should return something very close to 1.0). This means that in order\n",
    "# to compute the coside similarity, it's sufficient to \n",
    "# multiply the matrix `X` by the vector `v`:\n",
    "\n",
    "\n",
    "# ```python\n",
    "# scores = X.dot(v)\n",
    "# ```\n",
    "\n",
    "# calculating the cosine similarity between the user question and the documents\n",
    "v = embedding_model.encode(user_question)\n",
    "scores = np.dot(X, v)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65065753"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest score\n",
    "highest_score = scores.max()\n",
    "highest_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest score = 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector search\n",
    "\n",
    "We can now compute the similarity between a query vector and all the embeddings.\n",
    "\n",
    "Let's use this to implement our own vector search\n",
    "\n",
    "```python\n",
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "search_engine = VectorSearchEngine(documents=documents, embeddings=X)\n",
    "search_engine.search(v, num_results=5)\n",
    "```\n",
    "\n",
    "If you don't understand how the `search` function work:\n",
    "\n",
    "* Ask ChatGTP or any other LLM of your choice to explain the code\n",
    "* Check our pre-course workshop about implementing a search engine [here](https://github.com/alexeygrigorev/build-your-own-search-engine)\n",
    "\n",
    "(Note: you can replace `argsort` with `argpartition` to make it a lot faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'You can find the latest and up-to-date deadlines here: https://docs.google.com/spreadsheets/d/e/2PACX-1vQACMLuutV5rvXg5qICuJGL-yZqIV0FBD84CxPdC5eZHf8TfzB-CJT_3Mo7U7oGVTXmSihPgQxuuoku/pubhtml\\nAlso, take note of Announcements from @Au-Tomator for any extensions or other news. Or, the form may also show the updated deadline, if Instructor(s) has updated it.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Homework - What are homework and project deadlines?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'a1daf537'},\n",
       " {'text': 'After you submit your homework it will be graded based on the amount of questions in a particular homework. You can see how many points you have right on the page of the homework up top. Additionally in the leaderboard you will find the sum of all points you’ve earned - points for Homeworks, FAQs and Learning in Public. If homework is clear, others work as follows: if you submit something to FAQ, you get one point, for each learning in a public link you get one point.\\n(https://datatalks-club.slack.com/archives/C01FABYF2RG/p1706846846359379?thread_ts=1706825019.546229&cid=C01FABYF2RG)',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Homework and Leaderboard - what is the system for points in the course management platform?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '29865466'},\n",
       " {'text': \"There are 3 Zoom Camps in a year, as of 2024. However, they are for separate courses:\\nData-Engineering (Jan - Apr)\\nMLOps (May - Aug)\\nMachine Learning (Sep - Jan)\\nThere's only one Data-Engineering Zoomcamp “live” cohort per year, for the certification. Same as for the other Zoomcamps.\\nThey follow pretty much the same schedule for each cohort per zoomcamp. For Data-Engineering it is (generally) from Jan-Apr of the year. If you’re not interested in the Certificate, you can take any zoom camps at any time, at your own pace, out of sync with any “live” cohort.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - how many Zoomcamps in a year?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '2ed9b986'},\n",
       " {'text': 'Check Docker Compose File:\\nEnsure that your docker-compose.yaml file is correctly configured with the necessary details for the \"control-center\" service. Check the service name, image name, ports, volumes, environment variables, and any other configurations required for the container to start.\\nOn Mac OSX 12.2.1 (Monterey) I could not start the kafka control center. I opened Docker Desktop and saw docker images still running from week 4, which I did not see when I typed “docker ps.” I deleted them in docker desktop and then had no problem starting up the kafka environment.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Could not start docker image “control-center” from the docker-compose.yaml file.',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '70ac8e80'},\n",
       " {'text': 'You can set it up on your laptop or PC if you prefer to work locally from your laptop or PC.\\nYou might face some challenges, especially for Windows users. If you face cnd2\\nIf you prefer to work on the local machine, you may start with the week 1 Introduction to Docker and follow through.\\nHowever, if you prefer to set up a virtual machine, you may start with these first:\\nUsing GitHub Codespaces\\nSetting up the environment on a cloudV Mcodespace\\nI decided to work on a virtual machine because I have different laptops & PCs for my home & office, so I can work on this boot camp virtually anywhere.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Should I use my local machine, GCP, or GitHub Codespaces for my environment?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'ddf6c1b3'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "search_engine = VectorSearchEngine(documents=documents, embeddings=X)\n",
    "search_engine.search(v, num_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Hit-rate for our search engine\n",
    "\n",
    "Let's evaluate the performance of our own search engine. We will\n",
    "use the hitrate metric for evaluation.\n",
    "\n",
    "First, load the ground truth dataset:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "```\n",
    "\n",
    "Now use the code from the module to calculate the hitrate of\n",
    "`VectorSearchEngine` with `num_results=5`.\n",
    "\n",
    "What did you get?\n",
    "\n",
    "* 0.93\n",
    "* 0.73\n",
    "* 0.53\n",
    "* 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "\n",
    "v_q = embedding_model.encode(user_question)\n",
    "\n",
    "# def elastic_search_knn(field, vector, course):\n",
    "#     knn = {\n",
    "#         fi\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hit_rate(relevance_total):\n",
    "    count = 0\n",
    "    for relevance in relevance_total:\n",
    "        if True in relevance:\n",
    "            count += 1\n",
    "\n",
    "    return count / len(relevance_total)\n",
    "\n",
    "# # Now use the code from the module to calculate the hitrate of\n",
    "# # `VectorSearchEngine` with `num_results=5`.\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [doc['id'] == doc_id for doc in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return hit_rate(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1830 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[110], line 17\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(ground_truth, search_function)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m tqdm(ground_truth):\n\u001b[1;32m     16\u001b[0m     doc_id \u001b[38;5;241m=\u001b[39m q[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43msearch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     relevance \u001b[38;5;241m=\u001b[39m [doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m doc_id \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m     19\u001b[0m     relevance_total\u001b[38;5;241m.\u001b[39mappend(relevance)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_llm_zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
